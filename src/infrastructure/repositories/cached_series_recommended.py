import pickle
from typing import Generator

import redis

from src.domain import repositories
from src.domain.models import ItemFeatures


class SimpleSeriesRecommendedService:
    def __init__(self, ollama_url: str, model: str):
        self._ollama_url = ollama_url
        self._model = model

    def create_series_text(self, series):
        """–°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Å–µ—Ä–∏–∞–ª–∞"""
        parts = [f"–ù–∞–∑–≤–∞–Ω–∏–µ: {series['title']}", f"–û–ø–∏—Å–∞–Ω–∏–µ: {series['description']}"]

        if "genres" in series and series["genres"]:
            parts.append(f"–ñ–∞–Ω—Ä—ã: {', '.join(series['genres'])}")

        if "actors" in series and series["actors"]:
            parts.append(f"–ê–∫—Ç–µ—Ä—ã: {', '.join(series['actors'])}")

        if "year" in series:
            parts.append(f"–ì–æ–¥: {series['year']}")

        if "rating" in series:
            parts.append(f"–†–µ–π—Ç–∏–Ω–≥: {series['rating']}")

        return ". ".join(parts)

    def get_embedding(self, text):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ Ollama"""
        response = requests.post(f"{self._ollama_url}/api/embeddings", json={"model": self._model, "prompt": text})
        return response.json()["embedding"]

    def add_series(self, series_list):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–∏–∞–ª–æ–≤ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        self._series_data = series_list

        for series in self._series_data:
            # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–µ—Ä–∏–∞–ª–∞
            series_text = self.create_series_text(series)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            embedding = self.get_embedding(series_text)
            self._embeddings.append(embedding)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            series["_embedding_text"] = series_text

        self._embeddings = np.array(self._embeddings)

    def search(self, query, top_k=5):
        """–ü–æ–∏—Å–∫ –ø–æ –ª—é–±–æ–º—É —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É"""
        query_embedding = self.get_embedding(query)
        query_embedding = np.array(query_embedding).reshape(1, -1)

        similarities = cosine_similarity(query_embedding, self._embeddings)[0]

        results = []
        for idx in np.argsort(similarities)[::-1][:top_k]:
            results.append(
                {
                    "series": self._series_data[idx],
                    "similarity": similarities[idx],
                    "embedding_text": self._series_data[idx].get("_embedding_text", ""),
                }
            )

        return results


class CachedSeriesRecommenderRepository:
    def __init__(self, cache_repository: repositories.IDbRepository) -> None:
        self._cache_file = cache_file_name
        self._series_data = []
        self._embeddings = []
        self._cache_repository = cache_repository
        self._item_fields = [
            "id",
            "genres",
            "name",
            "persons",
            "short_description",
            "description",
            "slogan",
            "en_name",
        ]

    async def add_series(self, series_list):
        self._series_data = series_list

        async for batch_item_keys in self._cache_repository.get_all_item_keys():
            items = await self._cache_repository.get_item_features(batch_item_keys, features=self._item_fields)

            for item in items:
                item_dict = item.model_dump(exclude_defaults=True, exclude_none=True)
                item_text = ", ".join([f"{key}: {value}" for key, value in item_dict.items()])

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            embedding = self.get_embedding(series_text)
            self._embeddings.append(embedding)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            series["_embedding_text"] = series_text

        self._embeddings = np.array(self._embeddings)

    def save_embeddings(self):
        cache_data = {"series_data": self.series_data, "embeddings": self.embeddings}
        with open(self._cache_file, "wb") as f:
            pickle.dump(cache_data, f)

    def load_embeddings(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
        if Path(self._cache_file).exists():
            with open(self._cache_file, "rb") as f:
                cache_data = pickle.load(f)
                self.series_data = cache_data["series_data"]
                self.embeddings = cache_data["embeddings"]
            return True
        return False

    def add_series(self, series_list, use_cache=True):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–∏–∞–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—ç—à–∞"""
        if use_cache and self.load_embeddings():
            print("‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞")
            return

        print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        super().add_series(series_list)
        self.save_embeddings()
        print("‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à")
